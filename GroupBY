data = [(1,'manish',50000,'IT'),
(2,'vikash',60000,'sales'),
(3,'raushan',70000,'marketing'),
(4,'mukesh',80000,'IT'),
(5,'pritam',90000,'sales'),
(6,'nikita',45000,'marketing'),
(7,'ragini',55000,'marketing'),
(8,'rakesh',100000,'IT'),
(9,'aditya',65000,'IT'),
(10,'rahul',50000,'marketing')]

schema = ("id","name","salary","dept")

df = spark.createDataFrame(data=data,schema=schema)
df.show()



----------------------------------------------------------------------



from pyspark.sql import SparkSession
from pyspark.sql.functions import collect_list

# Initialize Spark session
spark = SparkSession.builder.appName("GroupByExample").getOrCreate()

# Create DataFrame
input_data = [("a", "aa", 1), ("a", "aa", 2), ("b", "bb", 3), ("b", "bb", 4), ("b", "bb", 5)]
columns = ["col1", "col2", "col3"]
df = spark.createDataFrame(input_data, columns)

# Perform groupBy and collect_list operation
result_df = df.groupBy("col1", "col2").agg(collect_list("col3").alias("col3"))

# Show result
result_df.show(truncate=False)
